---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home

---

<div align=center>
  <img src="assets/img/me.JPG" alt="me" style="zoom:25%;" />
</div>



Hi! This is Qianli Shen（沈千里）:) 

I’m a third-year PhD student at [School of Computing](https://www.comp.nus.edu.sg/),  [National University of Singapore](https://www.nus.edu.sg/), advised by [Prof. Kenji Kawaguchi](https://people.csail.mit.edu/kawaguch/). Previously, I completed my B.S. in Computer Science at [Peking University](http://english.pku.edu.cn/) in July 2020, advised by [Prof. Zhanxing Zhu](https://sites.google.com/view/zhanxingzhu/). In summer 2019, I visited [ISyE](https://www.isye.gatech.edu/), [Georgia Tech](https://www.gatech.edu/), working with [Prof. Tuo Zhao](https://www2.isye.gatech.edu/~tzhao80/). 

My research interest lies in using machine learning algorithms to solve practical problems.

Collaborations, discussions and chats are always welcome!

Email: <font color=Red>shenqianli [at] u.nus.edu </font>

[CV](assets/cv.pdf) / [Google Scholar](https://scholar.google.com/citations?user=p3ekN2kAAAAJ&hl=en) / [GitHub](https://github.com/ShenQianli) / [WeChat](assets/img/wechat.JPG) / [Ins](https://www.instagram.com/about311miles/) / [Twitter](https://www.twitter.com/ShenQianli)

<br>

[//]: # (<b><font size=5>Preprints</font></b>)

[//]: # (<p>)

[//]: # (<b><font size=3>The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline</font></b> [<a href="https://arxiv.org/abs/2401.04136">arxiv</a>][<a href="https:)

[//]: # (//github.com/haonan3/SilentBadDiffusion">code</a>])

[//]: # (<br>)

[//]: # (<font color=Grey>Haonan Wang, </font> <b>Qianli Shen</b><font color=Grey>, Yao Tong, Yang Zhang, Kenji Kawaguchi</font>)

[//]: # (<br>)

[//]: # (<font color=Grey><i> In Advances in Neural Information Processing Systems &#40;NeurIPS&#41;, 2023 &#40;BUGS Workshop, Oral&#41; </i></font> )

[//]: # (<br>)

[//]: # (<br>)

<b><font size=5>Publications</font></b>

<p>
<b><font size=3>Memory-Eﬀicient Gradient Unrolling for Large-Scale Bi-level Optimization</font></b> [<a href="https://arxiv.org/abs/2406.14095">arxiv</a>]
<br>
<font color=Grey></font> <b>Qianli Shen</b><font color=Grey>, Yezhen Wang, Zhouhao Yang, Xiang Li, Haonan Wang, Yang Zhang, Jonathon Scarlett, Zhanxing Zhu, Kenji Kawaguchi</font>
<br>
<font color=Grey><i>Preprint</i></font> 
<br>

<p>
<b><font size=3>FinerCut: Finer-grained Interpretable Layer Pruning for Large Language Models</font></b> [<a href="https://arxiv.org/abs/2405.18218">arxiv</a>]
<br>
<font color=Grey>Yang Zhang, Yawei Li, Xinpeng Wang, </font><b>Qianli Shen</b><font color=Grey>, Barbara Plank, Bernd Bischl, Mina Rezaei and Kenji Kawaguchi</font>
<br>
<font color=Grey><i>Preprint</i></font> 
<br>

<p>
<b><font size=3>The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline</font></b> [<a href="https://arxiv.org/abs/2401.04136">arxiv</a>][<a href="https:
//github.com/haonan3/SilentBadDiffusion">code</a>]
<br>
<font color=Grey>Haonan Wang, </font> <b>Qianli Shen</b><font color=Grey>, Yao Tong, Yang Zhang, Kenji Kawaguchi</font>
<br>
<font color=Grey><i> In Advances in Neural Information Processing Systems (NeurIPS), 2023 (BUGS Workshop, Oral) </i></font> 
<br>
<font color=Grey><i>International Conference on Machine Learning (ICML), 2024 (Oral, top 1.5%)</i></font> 
<br>

<p>
<b><font size=3>VA3: Virtually Assured Amplification Attack on Probabilistic Copyright Protection for Text-to-Image Generative Models</font></b> [<a href="https://arxiv.org/abs/2312.00057">arxiv</a>][<a href="https://github.com/South7X/VA3">code</a>]
<br>
<font color=Grey>Xiang Li*, </font> <b>Qianli Shen*</b><font color=Grey>, Kenji Kawaguchi</font>
<br>
<font color=Grey><i> Conference on Computer Vision and Pattern Recognition (CVPR), 2024 (Highlight, top 2.5%) </i></font> 
<br>

<p>
<b><font size=3>PICProp: Physics-Informed Confidence Propagation for Uncertainty Quantification</font></b> [<a href="http://arxiv.org/abs/2310.06923">arxiv</a>][<a href="https://github.com/ShenQianli/PICProp">code</a>]
<br>
<b>Qianli Shen</b><font color=Grey>, Wai Hoh Tang, Zhun Deng, Apostolos Psaros, Kenji Kawaguchi</font>
<br>
<font color=Grey><i>In Advances in Neural Information Processing Systems (NeurIPS), 2023</i></font> 
<br>

<p>
<b><font size=3>GFlowOut: Dropout with Generative Flow Networks</font></b> [<a href="https://arxiv.org/abs/2003.09534">arxiv</a>][<a href="https://github.com/kaiyuanmifen/GFNDropout">code</a>]
<br>
<font color=Grey>Dianbo Liu, Moksh Jain, Bonaventure F. P. Dossou, </font> <b>Qianli Shen</b><font color=Gray>, Salem Lahlou, Anirudh Goyal, Nikolay Malkin, Chris Chinenye Emezue, Dinghuai Zhang, Nadhir Hassen, Xu Ji, Kenji Kawaguchi, Yoshua Bengio</font>
<br>
<font color=Grey><i>International Conference on Machine Learning (ICML), 2023</i></font> 
<br>

<p>
<b><font size=3>Deep Reinforcement Learning with Robust and Smooth Policy</font></b> [<a href="https://arxiv.org/abs/2003.09534">arxiv</a>][<a href="https://www2.isye.gatech.edu/~tzhao80/III1717916/proj18_smooth.html">html</a>]  
<br>
<b>Qianli Shen*</b>, <font color=Gray>Yan Li*, Haoming Jiang, Zhaoran Wang, Tuo Zhao</font>
<br>
<font color=Grey><i>International Conference on Machine Learning (ICML), 2020</i></font> 
<br>
<br>

<b><font size=5>Softwares</font></b>

<p>
<b><font size=3>PRIMAL: PaRametric sImplex Method for spArse Learning</font></b> [<a href="https://github.com/ShenQianli/primal">GitHub</a>] 
<br>
<b>Qianli Shen*</b>, <font color=Gray>Zichong Li*, Yujia Xie and Tuo Zhao</font>
<br>
<br>

