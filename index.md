---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home

---

<div align="center">
  <img src="assets/img/qianli&newmoo.png" alt="Me" style="zoom: 8%;" />
</div>

# Welcome!

Hello! I am Qianli Shen (沈千里), a fourth-year PhD student at the [School of Computing](https://www.comp.nus.edu.sg/) at the [National University of Singapore](https://www.nus.edu.sg/), where I am advised by [Prof. Kenji Kawaguchi](https://people.csail.mit.edu/kawaguch/). I completed my B.S. in Computer Science at [Peking University](http://english.pku.edu.cn/) in July 2020, under the guidance of [Prof. Zhanxing Zhu](https://zhanxingzhu.github.io/). In the summer of 2019, I visited the [ISyE](https://www.isye.gatech.edu/) at [Georgia Tech](https://www.gatech.edu/) and worked with [Prof. Tuo Zhao](https://www2.isye.gatech.edu/~tzhao80/).

My research interests focus on leveraging machine learning algorithms to address practical problems.

I welcome collaborations, discussions, and casual chats!

**Email:** <span style="color: red;">shenqianli [at] u.nus.edu</span>

[CV](assets/cv.pdf) | [Google Scholar](https://scholar.google.com/citations?user=p3ekN2kAAAAJ&hl=en) | [GitHub](https://github.com/ShenQianli) | [WeChat](assets/img/wechat.JPG) | [Instagram](https://www.instagram.com/about311miles/) | [Twitter](https://www.twitter.com/ShenQianli)

<br>

<b><font size="5">Publications</font></b> <font size="3">(* indicates equal contribution)</font>

<p>
<b><font size="3" id="memory-efficient-gradient-unrolling-for-large-scale-bi-level-optimization">Memory-Efficient Gradient Unrolling for Large-Scale Bi-level Optimization</font></b> [<a href="https://arxiv.org/abs/2406.14095">arxiv</a>]
<br>
<b>Qianli Shen</b>, Yezhen Wang, Zhouhao Yang, Xiang Li, Haonan Wang, Yang Zhang, Jonathan Scarlett, Zhanxing Zhu, Kenji Kawaguchi
<br>
<i>In Advances in Neural Information Processing Systems (NeurIPS), 2024</i>
</p>

<p>
<b><font size="3" id="the-stronger-the-diffusion-model-the-easier-the-backdoor">The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline</font></b> [<a href="https://arxiv.org/abs/2401.04136">arxiv</a>][<a href="https://github.com/haonan3/SilentBadDiffusion">code</a>]
<br>
Haonan Wang, <b>Qianli Shen</b>, Yao Tong, Yang Zhang, Kenji Kawaguchi
<br>
<i>In Advances in Neural Information Processing Systems (NeurIPS), 2023 (BUGS Workshop, Oral)</i>
<br>
<i>International Conference on Machine Learning (ICML), 2024 (Oral, top 1.5%)</i>
</p>

<p>
<b><font size="3" id="va3-virtually-assured-amplification-attack-on-probabilistic-copyright-protection-for-text-to-image-generative-models">VA3: Virtually Assured Amplification Attack on Probabilistic Copyright Protection for Text-to-Image Generative Models</font></b> [<a href="https://arxiv.org/abs/2312.00057">arxiv</a>][<a href="https://github.com/South7X/VA3">code</a>]
<br>
Xiang Li*, <b>Qianli Shen*</b>, Kenji Kawaguchi
<br>
<i>Conference on Computer Vision and Pattern Recognition (CVPR), 2024 (Highlight, top 2.5%)</i>
</p>

<p>
<b><font size="3" id="picprop-physics-informed-confidence-propagation-for-uncertainty-quantification">PICProp: Physics-Informed Confidence Propagation for Uncertainty Quantification</font></b> [<a href="http://arxiv.org/abs/2310.06923">arxiv</a>][<a href="https://github.com/ShenQianli/PICProp">code</a>]
<br>
<b>Qianli Shen</b>, Wai Hoh Tang, Zhun Deng, Apostolos Psaros, Kenji Kawaguchi
<br>
<i>In Advances in Neural Information Processing Systems (NeurIPS), 2023</i>
</p>

<p>
<b><font size="3" id="gflowout-dropout-with-generative-flow-networks">GFlowOut: Dropout with Generative Flow Networks</font></b> [<a href="https://arxiv.org/abs/2003.09534">arxiv</a>][<a href="https://github.com/kaiyuanmifen/GFNDropout">code</a>]
<br>
Dianbo Liu, Moksh Jain, Bonaventure F. P. Dossou, <b>Qianli Shen</b>, Salem Lahlou, Anirudh Goyal, Nikolay Malkin, Chris Chinenye Emezue, Dinghuai Zhang, Nadhir Hassen, Xu Ji, Kenji Kawaguchi, Yoshua Bengio
<br>
<i>International Conference on Machine Learning (ICML), 2023</i>
</p>

<p>
<b><font size="3" id="deep-reinforcement-learning-with-robust-and-smooth-policy">Deep Reinforcement Learning with Robust and Smooth Policy</font></b> [<a href="https://arxiv.org/abs/2003.09534">arxiv</a>][<a href="https://www2.isye.gatech.edu/~tzhao80/III1717916/proj18_smooth.html">html</a>]  
<br>
<b>Qianli Shen*</b>, Yan Li*, Haoming Jiang, Zhaoran Wang, Tuo Zhao
<br>
<i>International Conference on Machine Learning (ICML), 2020</i>
</p>

<br>
<b><font size="5">Preprints</font></b>

<p>
<b><font size="3">State-Space Models are Accurate and Efficient Neural Operators for Dynamical Systems</font></b> [<a href="https://arxiv.org/pdf/2409.03231">arxiv</a>]
<br>
Zheyuan Hu, Nazanin Ahmadi Daryakenari, <b>Qianli Shen</b>, Kenji Kawaguchi, George Em Karniadakis
<br>
<i>Preprint</i>
</p>

<p>
<b><font size="3">FinerCut: Finer-grained Interpretable Layer Pruning for Large Language Models</font></b> [<a href="https://arxiv.org/abs/2405.18218">arxiv</a>]
<br>
Yang Zhang, Yawei Li, Xinpeng Wang, <b>Qianli Shen</b>, Barbara Plank, Bernd Bischl, Mina Rezaei, Kenji Kawaguchi
<br>
<i>Preprint</i>
</p>

<p>
<b><font size="3">State-Aware Proximal Pessimistic Algorithms for Offline Reinforcement Learning</font></b> [<a href="https://arxiv.org/abs/2211.15065">arxiv</a>]
<br>
Chen Chen, Hongyao Tang, Yi Ma, Chao Wang, <b>Qianli Shen</b>, Dong Li, Jianye Hao
<br>
<i>Preprint</i>
</p>

<br>
<b><font size="5">Softwares</font></b>

<p>
<b><font size=3>PRIMAL: PaRametric sImplex Method for spArse Learning</font></b> [<a href="https://github.com/ShenQianli/primal">GitHub</a>] 
<br>
<b>Qianli Shen*</b>, Zichong Li*, Yujia Xie and Tuo Zhao
<br>
</p>


